{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt MSP1\n",
    "Cílem tohoto projektu je se seznámit s programovými nástroji využívaných ve statistice a osvojit si základní procedury. Projekt není primárně zaměřen na efektivitu využívání programového vybavení (i když úplně nevhodné konstrukce mohou mít vliv na hodnocení), ale nejvíce nás zajímají vaše statistické závěry a způsob vyhodnocení. Dbejte také na to, že každý graf musí splňovat nějaké podmínky - přehlednost, čitelnost, popisky.\n",
    "\n",
    "V projektu budete analyzovat časy běhu šesti různých konfigurací algoritmů. Ke každé konfiguraci vzniklo celkem 200 nezávislých běhů, jejichž logy máte k dispozici v souboru [logfiles.zip](logfiles.zip).\n",
    "\n",
    "Pokud nemáte rozchozené prostředí pro pro spouštění Jupyter notebooku, můžete využití službu [Google Colab](https://colab.google/). Jakákoliv spolupráce, sdílení řešení a podobně je zakázána!\n",
    "\n",
    "S případnými dotazy se obracejte na Vojtěcha Mrázka (mrazek@fit.vutbr.cz).\n",
    "\n",
    "__Odevzdání:__ tento soubor (není potřeba aby obsahoval výstupy skriptů) do neděle 22. 10. 2023 v IS VUT. Kontrola bude probíhat na Pythonu 3.10.12; neočekává se však to, že byste používali nějaké speciality a nekompatibilní knihovny. V případě nesouladu verzí a podobných problémů budete mít možnost reklamace a prokázání správnosti funkce. Bez vyplnění vašich komentářů a závěrů do označených buněk nebude projekt hodnocen!\n",
    "\n",
    "__Upozornění:__ nepřidávejte do notebooku další buňky, odpovídejte tam, kam se ptáme (textové komentáře do Markdown buněk)\n",
    "\n",
    "__Tip:__ před odevzdáním resetujte celý notebook a zkuste jej spustit od začátku. Zamezíte tak chybám krokování a editací, kdy výsledek z buňky na konci použijete na začátku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_ Jméno a login autora_\n",
    "\n",
    "David Chocholatý, xchoch09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení potřebných knihoven\n",
    "Načtěte knihovny, které jsou nutné pro zpracování souborů a práci se statistickými funkcemi. Není dovoleno načítat jiné knihovny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení dat do DataFrame\n",
    "Ze souboru `logfiles.zip` umístěném ve stejném adresáři načtěte data a vytvořte Pandas DataFrame.\n",
    "\n",
    "Z logu vás budou nejvíce zajímat řádky\n",
    "```\n",
    "Configuration: config6\n",
    "Run: 191\n",
    "Time of run: 53.298725254089774\n",
    "```\n",
    "\n",
    "Můžete využít následující kostru - je vhodné pracovat přímo se ZIP souborem. Jedinou nevýhodou je to, že vám bude vracet _byte_ objekt, který musíte přes funkci `decode` zpracovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logfile(f) -> dict:\n",
    "    \"\"\"Load a logfile from a file-like object and return a dict with the data.\"\"\"\n",
    "    data = {\n",
    "        \"conf\": None,\n",
    "        \"run\": None,\n",
    "        \"time\": np.nan\n",
    "    }\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.decode(\"utf-8\")\n",
    "\n",
    "        # Odstranění znaku nového řádku a rozdělení řádku na páry klíč–hodnota.\n",
    "        [line_key, line_value] = line.strip().split(\": \")                                \n",
    "        \n",
    "        if line_key == \"Configuration\":\n",
    "            data[\"conf\"] = line_value\n",
    "        elif line_key == \"Run\":\n",
    "            data[\"run\"] = int(line_value)\n",
    "        elif line_key == \"Time of run\":            \n",
    "            data[\"time\"] = float(line_value)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = []\n",
    "with ZipFile(\"logfiles.zip\") as zf:\n",
    "    for filename in zf.namelist():\n",
    "        with zf.open(filename, \"r\") as f:\n",
    "            data.append(load_logfile(f))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analýza a čištění dat\n",
    "Vhodným způsobem pro všechny konfigurace analyzujte časy běhů a pokud tam jsou, identifikujte hodnoty, které jsou chybné. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "for figid, (conf, d) in enumerate(df.groupby(\"conf\")):\n",
    "    ax = plt.subplot(321 + figid)\n",
    "    ax.hist(d[\"time\"], label=conf, bins=200)\n",
    "    ax.set_title(conf)\n",
    "    ax.set(xlabel=\"Čas\", ylabel=\"Četnost\")\n",
    "\n",
    "plt.tight_layout()\n",
    "###################\n",
    "\n",
    "xlim_val = plt.xlim() # Uložení xlim hodnot (min, max) pro zobrazení grafů po odstranění chybných dat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Objevily se nějaké chybné hodnoty? Proč tam jsou s ohledem na to, že se jedná o běhy algoritmů?_\n",
    "\n",
    "Ano. V datech jsou uloženy také chybné hodnoty. Konkrétně lze označit hodnoty času (time) 0.01 a 3600 pro jednotlivé běhy (run) konfigurací (conf) za chybné.\n",
    "\n",
    "<u>Hodnota 0.01</u>:\n",
    "\n",
    "Zaprvé četnost zastoupení této časové hodnoty v datech je oproti ostatním hodnotam minimální. Zároveň tato časová hodnota je velmi _malá_ oproti dalším časovým hodnotám a hodnoty jí blízké nejsou v datech jinak zastoupeny.\n",
    "\n",
    "Na základě skutečnosti, že data zachycují jednotlivé běhy algoritmů, se s největší pravděpodobností jedná o ukončení programu s chybovým stavem, tudíž celý algoritmus nebyl proveden a byl předčasně ukončen. Při bližší analýze dat může být tato skutečnost potvrzena, že všechny běhy, jejichž čas odpovídal dané hodnotě, skončily s chybovým stavem SEGFAULT.\n",
    "\n",
    "<u>Hodnota 3600</u>:\n",
    "\n",
    "Zaprvé četnost zastoupení této časové hodnoty v datech je oproti ostatním hodnotam minimální. Zároveň tato časová hodnota je velmi _velká_ oproti dalším časovým hodnotám a hodnoty jí blízké nejsou v datech jinak zastoupeny.\n",
    "\n",
    "Na základě skutečnosti, že data zachycují jednotlivé běhy algoritmů, se s největší pravděpodobností jedná o ukončení programu na základě překročení času omezujícího dobu povolenou pro běh algoritmu (timeout) a došlo k nevalidnímu ukončení co se týče běhu algoritmu. Při bližší analýze dat může být tato skutečnost potvrzena, že všechny běhy, jejichž čas odpovídal dané hodnotě, skončily s chybovým stavem TIME LIMIT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyčistěte dataframe `df` tak, aby tam tyto hodnoty nebyly a ukažte znovu analýzu toho, že čištění dat bylo úspěšné. Odtud dále pracujte s vyčištěným datasetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vyčištění chybných hodnot (0.01 a 3600)\n",
    "df = df[(df.time > 0.01) & (df.time < 3600)]\n",
    "\n",
    "# Znovuvykreslení dat    \n",
    "plt.figure(figsize=(12,10))\n",
    "plt.suptitle(\" Grafy pro ověření správnosti čištění dat: \", fontsize=20)\n",
    "for figid, (conf, d) in enumerate(df.groupby(\"conf\")):\n",
    "    ax = plt.subplot(321 + figid)\n",
    "    ax.hist(d[\"time\"], label=conf, bins=200)\n",
    "    ax.set_title(conf)   \n",
    "    ax.set(xlabel=\"Čas\", ylabel=\"Četnost\")\n",
    "    ax.set_xlim(xlim_val)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.suptitle(\" Zobrazení dat v přívětivější podobě: \", fontsize=20)\n",
    "for figid, (conf, d) in enumerate(df.groupby(\"conf\")):\n",
    "    ax = plt.subplot(321 + figid)\n",
    "    ax.hist(d[\"time\"], label=conf, bins=30)\n",
    "    ax.set_title(conf)\n",
    "    ax.set(xlabel=\"Čas\", ylabel=\"Četnost\")\n",
    "    ax.set_xlim(0, 300)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deskriptivní popis hodnot\n",
    "Vypište pro jednotlivé konfigurace základní deskriptivní parametry času pro jednotlivé konfigurace.  \n",
    "\n",
    "__TIP__ pokud výsledky uložíte jako Pandas DataFrame, zobrazí se v tabulce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"conf\")[\"time\"]\n",
    "\n",
    "print(\"Koeficient šikmosti\")\n",
    "print(\"###################\")\n",
    "print(df_grouped.skew())\n",
    "print()\n",
    "\n",
    "print(\"Koeficient špičatosti\")\n",
    "print(\"###################\")\n",
    "print(df_grouped.apply(pd.DataFrame.kurt))\n",
    "print()\n",
    "\n",
    "print(\"Další základní deskriptivní parametry\")\n",
    "print(\"######################################\")\n",
    "df_grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Okomentujte, co všechno můžeme z parametrů vyčíst._\n",
    "\n",
    "<u>count</u>:\n",
    "\n",
    "Nejprve si můžeme povšimnout, že na základě hodnoty \"count\" každá z konfigurací měla nějaký \"run\", kdy skončila chybovým stavem nebo běh překročil maximální časový limit. Nejmenší chybovosti dosahuje konfigurace *config4* a největší konfigurace *config1*.\n",
    "\n",
    "<u>mean</u>:\n",
    "\n",
    "Na základě získaných a pozorovaných dat se mezi konfigurace s nejmenší průměrnou dobou běhu řadí konfigurace *config1* a *config4*, přičemž konfigurace *config1* má nejměnší průměrnou hodnotu doby běhu algoritmu.\n",
    "\n",
    "Dále mezi konfigurace s největší průměrnou dobou běhu se řadí konfigurace *config5* a *config6*, přičemž konfigurace *config5* má největší průměrnou hodnotu doby běhu algoritmu.\n",
    "\n",
    "<u>std</u>:\n",
    "\n",
    "Z dat směrodatných odchylek všech konfigurací vyplývá, že rozptyl naměřených hodnot je nejmenší pro konfiguraci *config1* a největší pro konfiguraci *config4*.\n",
    "\n",
    "<u>min</u>:\n",
    "\n",
    "V datech je zachyceno, že nejmenší časovou hodnotu doby běhu algoritmu mají konfigurace *config4* a *config1*. Na druhé straně konfigurace *config5* a *config6* mají nejvyšší minimální dobu běhu.\n",
    "\n",
    "<u>25%, 50%, 75%</u>:\n",
    "\n",
    "Dle hodnot percentilů pro jednotlivé konfigurace lze určit, že nejmenší časové hodnoty, ve kterých je 25%, 50% a 75% dat, mají konfigurace *config1* a *config4*. Naopak nejvyšší hodnoty mají konfigurace *config5* a *config6*.\n",
    "\n",
    "<u>max</u>:\n",
    "\n",
    "Z pozorování dat vyplývá, že v parametru nejdelší doby validně ukončeného běhu konfigurace dominuje konfigurace *config1* s nejmenší časovou hodnotou. Naopak na druhé straně škály se nachází konfigurace *config5*.\n",
    "\n",
    "<u>Koeficient šikmosti</u>:\n",
    "\n",
    "Hodnota koeficientu určuje symetričnost dat. Zároveň pro normální rozdělení by mělo platit, že hodnota je blízká hodnotě 0, což lze ze získaných dat potvrdit.\n",
    "\n",
    "<u>Koeficient špičatosti</u>:\n",
    "\n",
    "Na základě hodnot koeficientu šikmosti lze pomocí hodnot koeficientu špičatosti blízkých 0 rozhodnout, že ve všech případech konfigurací se jedná o normální rozdělení.\n",
    "\n",
    "Sumarizace:\n",
    "Na základě analýzy dat lze usoudit, že konfigurace *config1* a *config4* mohou být potenciálně nejlepší, co se týče časové optimálnosti algoritmu. Naopak potenciálně nejhorší jsou konfigurace *config5* a *config6*. S využitím hodnot koeficientů šikmosti a špičatosti lze tvrdit, že pro všechny konfigurace se jedná o normální rozdělení."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizace\n",
    "Vizualizujte časy běhů algoritmů v jednom kompaktním grafu tak, aby byl zřejmý i rozptyl hodnot. Zvolte vhodný graf, který pak níže komentujte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.boxplot(df.groupby(\"conf\")[\"time\"].apply(list), labels=df.conf.unique())\n",
    "ax.set(xlabel=\"Konfigurace\", ylabel=\"Čas\", ylim=(0, None))\n",
    "ax.set_title(\"Časy běhů algoritmů\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Okomentujte  výsledky z tabulky._\n",
    "\n",
    "Z vizualizace ve formě Boxplot lze potvrdit na základě minimálních hodnot, mediánu a interkvartilního rozsahu, že pro bližší zkoumání by měly být vybrány konfigurace *config1* a *config4*. Zároveň lze pozorovat, že hodnoty interkvartilního rozsahu a mediánu jsou nejmenší pro konfiguraci *config1* a lze prozatím předpokládat, že se jedná o nejoptimálnější konfiguraci.\n",
    "\n",
    "Na základě rozdílné \"výšky boxů\" v grafu můžeme určit, že pro určení efektivity konfigurací bude vhodné použit nepárový T-test (Welchův test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Určení efektivity konfigurací algoritmů\n",
    "Nás ale zajímá, jaká konfigurace je nejrychlejší. Z výše vykresleného grafu můžeme vyloučit některé konfigurace. Existuje tam však minimálně jedna dvojice, u které nedokážeme jednoznačně určit, která je lepší - pokud nebudeme porovnávat pouze extrémní hodnoty, které mohou být dané náhodou, ale celkově. Proto proveďte vhodný test významnosti - v následující části diskutujte zejména rozložení dat (i s odkazem na předchozí buňky, variabilitu vs polohu a podobně). Je nutné každý logický krok a výběry statistických funkcí komentovat. Můžete i přidat další buňky.\n",
    "\n",
    "Vužijte vhodnou funkci z knihovny `scipy.stats` a funkci poté __implementujte sami__ na základě základních matematických funkcí knihovny `numpy` případně i funkcí pro výpočet studentova rozložení v [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html). Při vlastní implementaci není nutné se primárně soustředit na efektivitu výpočtu (není potřeba využít všechny funkce numpy, můžete použít normální cykly a podobně - v hodnocení však bude zahrnuta přehlednost a neměly by se objevit jasné chyby, jako je zvýšení třídy složitosti a podobně)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Jaká data budete zkoumat? Jaké mají rozložení a parametry (např. varianci) a jaký test použijete? Jaká je nulová hypotéza? Jak se liší variabilita a poloha vybraných konfigurací?_\n",
    "\n",
    "Na základě předchozích analýz bylo rozhodnuto, že pro další zkoumání budou vybrány konfigurace *config1* a *config4*. Bylo zjištěno, že ve všech případech se jedná o normální rozdělení. Jak již bylo uvedeno, použijeme nepárový T-test, a to konkrétně Welchův test. Volbu tohoto testu lze argumentovat rozdílnou variancí (**variabilita**) dat pro vybrané konfigurace. Na základě skutečnosti, že medián (**poloha**) hodnot pro konfiguraci *config1* je menší než medián hodnot pro konfiguraci *config4*, bude nulová a alternativní hypotéza stanovena následovně.\n",
    "\n",
    "<u>Nulová hypotéza</u>\n",
    "\n",
    "Oba vzorky musí mít stejnou průměrnou hodnotu.\n",
    "\n",
    "<u>Alternativní hypotéza</u>\n",
    "\n",
    "Průměrná hodnota distribuce pro *config1* je menší než průměrná hodnota distribuce pro *config4*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_1 = df[(df.conf == \"config1\")][\"time\"]\n",
    "config_4 = df[(df.conf == \"config4\")][\"time\"]\n",
    "\n",
    "statistical_significance = 0.05\n",
    "\n",
    "print(\"T-test\")\n",
    "print(\"####################################\")\n",
    "\n",
    "# Alternative (less): config1 < config4\n",
    "result_ttest = stats.ttest_ind_from_stats(config_1.mean(), config_1.std(), len(config_1),\n",
    "                                          config_4.mean(), config_4.std(), len(config_4),\n",
    "                                          equal_var=False, alternative=\"less\")\n",
    "\n",
    "print(\"statistic =\", result_ttest.statistic)\n",
    "print(\"pvalue =\", result_ttest.pvalue)\n",
    "print()\n",
    "\n",
    "if result_ttest.pvalue < statistical_significance:\n",
    "    print(\"Nulová hypotéza se zamítá a platí alternativní hypotéza.\")\n",
    "else:\n",
    "    print(\"Nulová hypotéza se nezamítá.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Jaký je závěr statistického testu?_\n",
    "\n",
    "Na základě výsledku testu zamítáme alternativní hypotézu a platí alternativní hypotéza. Celkovým výsledkem bylo stanoveno, že konfigurace *config1* je efektivnější než konfigurace *config4*. Zároveň dle výsledků předchozí analýzy vyplývá, že konfigurace *config1* je nejefektivnější konfigurací ze všech zkoumaných."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Student%27s_t-test#Independent_two-sample_t-test\n",
    "def independent_two_sample_ttest(s_1, nobs_1, s_2, nobs_2):        \n",
    "    degrees_of_freedom = nobs_1 + nobs_2 - 2.0\n",
    "    svar = ((nobs_1 - 1) * s_1 + (nobs_2 - 1) * s_2) / degrees_of_freedom\n",
    "    divisor = np.sqrt(svar * (1.0 / nobs_1 + 1.0 / nobs_2))\n",
    "    \n",
    "    return degrees_of_freedom, divisor\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
    "def welchs_ttest(s_1, nobs_1, s_2, nobs_2):\n",
    "    sn_1 = s_1 / nobs_1\n",
    "    sn_2 = s_2 / nobs_2\n",
    "        \n",
    "    try:\n",
    "        degrees_of_freedom = (sn_1 + sn_2)**2 / (sn_1**2 / (nobs_1 - 1) + sn_2**2 / (nobs_2 - 1))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Info: Division by zero, setting to 0.0.\")        \n",
    "        degrees_of_freedom = 0.0\n",
    "\n",
    "    divisor = np.sqrt(sn_1 + sn_2)\n",
    "    \n",
    "    return degrees_of_freedom, divisor\n",
    "\n",
    "def own_ttest_ind_from_stats(mean_1, std_1, nobs_1, mean_2, std_2, nobs_2,\n",
    "                             equal_var=True, alternative=\"two-sided\"):\n",
    "    mean_1 = np.asarray(mean_1)\n",
    "    std_1 = np.asarray(std_1)\n",
    "    mean_2 = np.asarray(mean_2)\n",
    "    std_2 = np.asarray(std_2)\n",
    "\n",
    "    s_1 = std_1**2\n",
    "    s_2 = std_2**2\n",
    "    \n",
    "    if equal_var:\n",
    "        degrees_of_freedom, divisor = independent_two_sample_ttest(s_1, nobs_1, s_2, nobs_2)\n",
    "    else:\n",
    "        degrees_of_freedom, divisor = welchs_ttest(s_1, nobs_1, s_2, nobs_2)\n",
    "    \n",
    "    diff = (mean_1 - mean_2)\n",
    "    \n",
    "    if divisor == 0.0:\n",
    "        print(\"Info: Division by zero, setting to 0.0.\")        \n",
    "        t = 0.0\n",
    "    else:\n",
    "        t = np.divide(diff, divisor)    \n",
    "    \n",
    "    if alternative == \"two-sided\":\n",
    "        p_value = stats.t.cdf(-np.abs(t), degrees_of_freedom)*2\n",
    "    elif alternative == \"less\":\n",
    "        p_value = stats.t.cdf(t, degrees_of_freedom)        \n",
    "    elif alternative == \"greater\":\n",
    "        p_value = stats.t.cdf(-t, degrees_of_freedom)   \n",
    "    else:\n",
    "        raise ValueError(\"(alternative) - one of the following must to be provided: two-sided, less or greater\")\n",
    "    \n",
    "    return t, p_value\n",
    "\n",
    "print(\"T-test\")\n",
    "print(\"####################################\")\n",
    "\n",
    "t, p_value = own_ttest_ind_from_stats(config_1.mean(), config_1.std(), len(config_1), config_4.mean(), config_4.std(), len(config_4), equal_var=False, alternative=\"less\")\n",
    "\n",
    "print(\"statistic =\", t)\n",
    "print(\"pvalue =\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
